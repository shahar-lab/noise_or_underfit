{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "\n",
    "from mf_sim import *\n",
    "from mf_fit import *\n",
    "from mf_predict import *\n",
    "\n",
    "from mb_sim import *\n",
    "from mb_fit import *\n",
    "from mb_predict import *\n",
    "\n",
    "from habit_sim import *\n",
    "from habit_fit import *\n",
    "from habit_predict import *\n",
    "\n",
    "from wsls_sim import *\n",
    "from wsls_fit import *\n",
    "from wsls_predict import *\n",
    "\n",
    "from kdh_sim import *\n",
    "from kdh_fit import *\n",
    "from kdh_predict import *\n",
    "\n",
    "from utils import *\n",
    "from plot_stats import *\n",
    "from logistic_regression import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config num of agent to simulate\n",
    "num_of_agents = 100\n",
    "\n",
    "#config num of trails for each block\n",
    "num_of_trials = 200\n",
    "\n",
    "num_of_block = 5\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "reversal = 50\n",
    "\n",
    "# create transtion probs\n",
    "transtion_probs = np.array([[.8,.2],\n",
    "                            [.2,.8]])\n",
    "\n",
    "models = {\n",
    "        'mf':[configuration_parameters_mf, mf_sim],\n",
    "        'mb':[configuration_parameters_mb, mb_sim],\n",
    "        'habit':[configuration_parameters_habits,habit_sim],\n",
    "        'wsls':[configuration_parameters_wsls,wsls_sim],\n",
    "        'kdh':[configuration_parameters_kdh,kdh_sim]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c036369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:09<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:09<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model habit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:08<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model wsls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:08<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:07<00:00, 13.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# sim\n",
    "for m in models:\n",
    "    print(f'Model {m}')\n",
    "    \n",
    "    data_per_agent = []\n",
    "    parameters = []\n",
    "\n",
    "    for agent in tqdm(range(num_of_agents)):\n",
    "        param = models[m][0]()\n",
    "        parameters.append(param)\n",
    "        \n",
    "        data = []\n",
    "        for i in range(num_of_block):\n",
    "            # create rewards probs \n",
    "            reward_probs = create_reward_probs(num_of_trials,reversal,0.2,0.8)\n",
    "            df = models[m][1](\n",
    "                            param,\n",
    "                            num_of_trials,\n",
    "                            transtion_probs,\n",
    "                            reward_probs\n",
    "            ) \n",
    "            data.append(df)\n",
    "        data_per_agent.append(data)\n",
    "\n",
    "    df = pd.DataFrame(parameters)\n",
    "    df.to_csv(f'../results/{m}/{m}_parameters.csv')\n",
    "    \n",
    "    for agent in range(num_of_agents):\n",
    "        for block in range(num_of_block):\n",
    "            data_per_agent[agent][block].to_csv(f'../data/{m}/{m}_agent_{agent}_sim_{block}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e899b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                      | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit mf ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "for m in tqdm(models):    \n",
    "    # load data \n",
    "    data_per_agent = []\n",
    "    for agent in range(num_of_agents):\n",
    "        data = []\n",
    "        for sim in range(num_of_block):\n",
    "            data.append(pd.read_csv(f'../data/{m}/{m}_agent_{agent}_sim_{sim}.csv'))\n",
    "        data_per_agent.append(data)\n",
    "        \n",
    "    data_results = {\n",
    "                   'agent': [], \n",
    "                   'fit_parameters_mf': [], \n",
    "                   'train_nlp_mf' : [], \n",
    "                   'test_acc_mf': [],\n",
    "                   'test_nlp_mf': [], \n",
    "\n",
    "                   'fit_parameters_mb': [], \n",
    "                   'train_nlp_mb' : [], \n",
    "                   'test_acc_mb': [],\n",
    "                   'test_nlp_mb': [],\n",
    "        \n",
    "                   'fit_parameters_habit': [], \n",
    "                   'train_nlp_habit' : [], \n",
    "                   'test_acc_habit': [],\n",
    "                   'test_nlp_habit': [], \n",
    "        \n",
    "                    'fit_parameters_wsls': [], \n",
    "                   'train_nlp_wsls' : [], \n",
    "                   'test_acc_wsls': [],\n",
    "                   'test_nlp_wsls': [], \n",
    "\n",
    "                   'fit_parameters_kdh': [], \n",
    "                   'train_nlp_kdh' : [], \n",
    "                   'test_acc_kdh': [],\n",
    "                   'test_nlp_kdh': [], \n",
    "\n",
    "                   'fit_parameters_logistic_regression': [], \n",
    "                   'train_nlp_logistic_regression' : [], \n",
    "                   'test_acc_logistic_regression': [],\n",
    "                   'test_nlp_logistic_regression': [],\n",
    "\n",
    "            }\n",
    "    print(f'*** Fit {m} ***')\n",
    "    for agent in range(num_of_agents):\n",
    "        print(f'* agent {agent} *')\n",
    "        for n,t in enumerate(cv):\n",
    "            data_results['agent'].append(agent)\n",
    "            train_arr = t[0:-1]\n",
    "            test_arr = t[-1:]\n",
    "\n",
    "            # split train and test data\n",
    "            train_data = [data_per_agent[agent][sim] for sim in train_arr]\n",
    "            train_data = pd.concat(train_data) \n",
    "            train_data.reset_index(inplace=True)\n",
    "            n_train = len(train_data)\n",
    "\n",
    "            test_data = [data_per_agent[agent][sim] for sim in test_arr]\n",
    "            test_data = pd.concat(test_data) \n",
    "            test_data.reset_index(inplace=True)\n",
    "            n_test = len(test_data)\n",
    "            \n",
    "            # fit mf \n",
    "            res = mf_fit(train_data,2)\n",
    "            data_results['fit_parameters_mf'].append(res.x)\n",
    "\n",
    "            # Train log probability\n",
    "            data_results['train_nlp_mf'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = mf_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mf'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mf'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit mb\n",
    "            res = mb_fit(train_data,2)\n",
    "            data_results['fit_parameters_mb'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_mb'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = mb_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mb'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mb'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit habit\n",
    "            res = habit_fit(train_data,2)\n",
    "            data_results['fit_parameters_habit'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_habit'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = habit_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_habit'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_habit'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit wsls\n",
    "            res = wsls_fit(train_data,2)\n",
    "            data_results['fit_parameters_wsls'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_wsls'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = wsls_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_wsls'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_wsls'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit kDH\n",
    "            res = kdh_fit(train_data,2)\n",
    "            data_results['fit_parameters_kdh'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_kdh'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = kdh_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_kdh'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_kdh'].append((running_loss/n_test))\n",
    "\n",
    "            X , y = preprocess_logistic_regression(train_data)\n",
    "            model, intercept, coef  = fit_logistic_regression(X,y)\n",
    "            data_results['fit_parameters_logistic_regression'].append([intercept,coef])\n",
    "\n",
    "            # Train negative log probability\n",
    "            nlp = nlp_logistic_regression(model,X,y)\n",
    "            data_results['train_nlp_logistic_regression'].append((nlp/n_train))\n",
    "\n",
    "            # test data \n",
    "            X, y = preprocess_logistic_regression(test_data)\n",
    "            # Test Accuracy\n",
    "            accuracy = model.score(X,y)\n",
    "            data_results['test_acc_logistic_regression'].append(accuracy)\n",
    "\n",
    "            # Test negative log probability\n",
    "            nlp = nlp_logistic_regression(model,X,y)\n",
    "            data_results['test_nlp_logistic_regression'].append((nlp/n_test))\n",
    "\n",
    "\n",
    "            \n",
    "    print(f'** save results {m} **')\n",
    "    # save data \n",
    "    df = pd.DataFrame(data_results)\n",
    "    df.to_csv(f'../results/{m}/{m}_fit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
