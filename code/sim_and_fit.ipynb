{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import*\n",
    "\n",
    "from mf_sim import *\n",
    "from mf_fit import *\n",
    "from mf_predict import *\n",
    "\n",
    "from mb_sim import *\n",
    "from mb_fit import *\n",
    "from mb_predict import *\n",
    "\n",
    "from habit_sim import *\n",
    "from habit_fit import *\n",
    "from habit_predict import *\n",
    "\n",
    "from wsls_sim import *\n",
    "from wsls_fit import *\n",
    "from wsls_predict import *\n",
    "\n",
    "from kdh_sim import *\n",
    "from kdh_fit import *\n",
    "from kdh_predict import *\n",
    "\n",
    "from utils import *\n",
    "from plot_stats import *\n",
    "from logistic_regression import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config num of agent to simulate\n",
    "num_of_agents = 100\n",
    "\n",
    "#config num of trails for each block\n",
    "num_of_trials = 200\n",
    "\n",
    "num_of_block = 5\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "reversal = 50\n",
    "\n",
    "# create transtion probs\n",
    "transtion_probs = np.array([[.8,.2],\n",
    "                            [.2,.8]])\n",
    "\n",
    "models = {\n",
    "        'mf':[configuration_parameters_mf, mf_sim],\n",
    "        'mb':[configuration_parameters_mb, mb_sim],\n",
    "        'habit':[configuration_parameters_habits,habit_sim],\n",
    "        'wsls':[configuration_parameters_wsls,wsls_sim],\n",
    "        'kdh':[configuration_parameters_kdh,kdh_sim]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c036369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:09<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:08<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model habit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:08<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model wsls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:07<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 100/100 [00:07<00:00, 13.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# sim\n",
    "for m in models:\n",
    "    print(f'Model {m}')\n",
    "    \n",
    "    data_per_agent = []\n",
    "    parameters = []\n",
    "\n",
    "    for agent in tqdm(range(num_of_agents)):\n",
    "        param = models[m][0]()\n",
    "        parameters.append(param)\n",
    "        \n",
    "        data = []\n",
    "        for i in range(num_of_block):\n",
    "            # create rewards probs \n",
    "            reward_probs = create_reward_probs(num_of_trials,reversal,0.2,0.8)\n",
    "            df = models[m][1](\n",
    "                            param,\n",
    "                            num_of_trials,\n",
    "                            transtion_probs,\n",
    "                            reward_probs\n",
    "            ) \n",
    "            data.append(df)\n",
    "        data_per_agent.append(data)\n",
    "\n",
    "    df = pd.DataFrame(parameters)\n",
    "    df.to_csv(f'../results/{m}/{m}_parameters.csv')\n",
    "    \n",
    "    for agent in range(num_of_agents):\n",
    "        for block in range(num_of_block):\n",
    "            data_per_agent[agent][block].to_csv(f'../data/{m}/{m}_agent_{agent}_sim_{block}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97e899b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                      | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit mf ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results mf **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████████                                    | 1/5 [08:23<33:35, 503.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit mb ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results mb **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████                           | 2/5 [16:32<24:44, 494.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit habit ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results habit **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████                  | 3/5 [24:27<16:11, 485.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit wsls ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results wsls **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████         | 4/5 [30:27<07:16, 436.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit kdh ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results kdh **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [42:55<00:00, 515.16s/it]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "for m in tqdm(models):    \n",
    "    # load data \n",
    "    data_per_agent = []\n",
    "    for agent in range(num_of_agents):\n",
    "        data = []\n",
    "        for sim in range(num_of_block):\n",
    "            data.append(pd.read_csv(f'../data/{m}/{m}_agent_{agent}_sim_{sim}.csv'))\n",
    "        data_per_agent.append(data)\n",
    "        \n",
    "    data_results = {\n",
    "                   'agent': [], \n",
    "                   'fit_parameters_mf': [], \n",
    "                   'train_nlp_mf' : [], \n",
    "                   'test_acc_mf': [],\n",
    "                   'test_nlp_mf': [], \n",
    "\n",
    "                   'fit_parameters_mb': [], \n",
    "                   'train_nlp_mb' : [], \n",
    "                   'test_acc_mb': [],\n",
    "                   'test_nlp_mb': [],\n",
    "        \n",
    "                   'fit_parameters_habit': [], \n",
    "                   'train_nlp_habit' : [], \n",
    "                   'test_acc_habit': [],\n",
    "                   'test_nlp_habit': [], \n",
    "        \n",
    "                    'fit_parameters_wsls': [], \n",
    "                   'train_nlp_wsls' : [], \n",
    "                   'test_acc_wsls': [],\n",
    "                   'test_nlp_wsls': [], \n",
    "\n",
    "                   'fit_parameters_kdh': [], \n",
    "                   'train_nlp_kdh' : [], \n",
    "                   'test_acc_kdh': [],\n",
    "                   'test_nlp_kdh': [], \n",
    "\n",
    "                   'fit_parameters_logistic_regression': [], \n",
    "                   'train_nlp_logistic_regression' : [], \n",
    "                   'test_acc_logistic_regression': [],\n",
    "                   'test_nlp_logistic_regression': [],\n",
    "\n",
    "            }\n",
    "    print(f'*** Fit {m} ***')\n",
    "    for agent in range(num_of_agents):\n",
    "        print(f'* agent {agent} *')\n",
    "        for n,t in enumerate(cv):\n",
    "            data_results['agent'].append(agent)\n",
    "            train_arr = t[0:-1]\n",
    "            test_arr = t[-1:]\n",
    "\n",
    "            # split train and test data\n",
    "            train_data = [data_per_agent[agent][sim] for sim in train_arr]\n",
    "            train_data = pd.concat(train_data) \n",
    "            train_data.reset_index(inplace=True)\n",
    "            n_train = len(train_data)\n",
    "\n",
    "            test_data = [data_per_agent[agent][sim] for sim in test_arr]\n",
    "            test_data = pd.concat(test_data) \n",
    "            test_data.reset_index(inplace=True)\n",
    "            n_test = len(test_data)\n",
    "            \n",
    "            # fit mf \n",
    "            res = mf_fit(train_data,2)\n",
    "            data_results['fit_parameters_mf'].append(res.x)\n",
    "\n",
    "            # Train log probability\n",
    "            data_results['train_nlp_mf'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = mf_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mf'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mf'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit mb\n",
    "            res = mb_fit(train_data,2)\n",
    "            data_results['fit_parameters_mb'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_mb'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = mb_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mb'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mb'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit habit\n",
    "            res = habit_fit(train_data,2)\n",
    "            data_results['fit_parameters_habit'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_habit'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = habit_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_habit'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_habit'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit wsls\n",
    "            res = wsls_fit(train_data,2)\n",
    "            data_results['fit_parameters_wsls'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_wsls'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = wsls_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_wsls'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_wsls'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit kDH\n",
    "            res = kdh_fit(train_data,2)\n",
    "            data_results['fit_parameters_kdh'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_kdh'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0 = kdh_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_kdh'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_kdh'].append((running_loss/n_test))\n",
    "\n",
    "            X , y = preprocess_logistic_regression(train_data)\n",
    "            model, intercept, coef  = fit_logistic_regression(X,y)\n",
    "            data_results['fit_parameters_logistic_regression'].append([intercept,coef])\n",
    "\n",
    "            # Train negative log probability\n",
    "            nlp = nlp_logistic_regression(model,X,y)\n",
    "            data_results['train_nlp_logistic_regression'].append((nlp/n_train))\n",
    "\n",
    "            # test data \n",
    "            X, y = preprocess_logistic_regression(test_data)\n",
    "            # Test Accuracy\n",
    "            accuracy = model.score(X,y)\n",
    "            data_results['test_acc_logistic_regression'].append(accuracy)\n",
    "\n",
    "            # Test negative log probability\n",
    "            nlp = nlp_logistic_regression(model,X,y)\n",
    "            data_results['test_nlp_logistic_regression'].append((nlp/n_test))\n",
    "\n",
    "\n",
    "            \n",
    "    print(f'** save results {m} **')\n",
    "    # save data \n",
    "    df = pd.DataFrame(data_results)\n",
    "    df.to_csv(f'../results/{m}/{m}_fit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270b3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f44e9_row0_col0, #T_f44e9_row1_col1, #T_f44e9_row2_col2, #T_f44e9_row4_col4, #T_f44e9_row5_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row0_col1 {\n",
       "  background-color: #26828e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row0_col2 {\n",
       "  background-color: #a0da39;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row0_col3 {\n",
       "  background-color: #93d741;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row0_col4 {\n",
       "  background-color: #5ac864;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row1_col0 {\n",
       "  background-color: #23888e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row1_col2 {\n",
       "  background-color: #b5de2b;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row1_col3 {\n",
       "  background-color: #dde318;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row1_col4, #T_f44e9_row4_col0, #T_f44e9_row4_col1, #T_f44e9_row4_col2, #T_f44e9_row4_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row2_col0 {\n",
       "  background-color: #31668e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row2_col1 {\n",
       "  background-color: #29798e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row2_col3 {\n",
       "  background-color: #4ec36b;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row2_col4 {\n",
       "  background-color: #23a983;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row3_col0 {\n",
       "  background-color: #3e4a89;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row3_col1 {\n",
       "  background-color: #238a8d;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row3_col2 {\n",
       "  background-color: #481f70;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row3_col3 {\n",
       "  background-color: #450559;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row3_col4 {\n",
       "  background-color: #7ad151;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row5_col0 {\n",
       "  background-color: #3f4788;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row5_col1 {\n",
       "  background-color: #38598c;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row5_col2 {\n",
       "  background-color: #481c6e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_f44e9_row5_col4 {\n",
       "  background-color: #6ece58;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f44e9_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >true_mf</th>\n",
       "      <th class=\"col_heading level0 col1\" >true_mb</th>\n",
       "      <th class=\"col_heading level0 col2\" >true_habit</th>\n",
       "      <th class=\"col_heading level0 col3\" >true_wsls</th>\n",
       "      <th class=\"col_heading level0 col4\" >true_kdh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row0\" class=\"row_heading level0 row0\" >fit_mf</th>\n",
       "      <td id=\"T_f44e9_row0_col0\" class=\"data row0 col0\" >0.396000</td>\n",
       "      <td id=\"T_f44e9_row0_col1\" class=\"data row0 col1\" >0.564000</td>\n",
       "      <td id=\"T_f44e9_row0_col2\" class=\"data row0 col2\" >0.676000</td>\n",
       "      <td id=\"T_f44e9_row0_col3\" class=\"data row0 col3\" >0.661000</td>\n",
       "      <td id=\"T_f44e9_row0_col4\" class=\"data row0 col4\" >0.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row1\" class=\"row_heading level0 row1\" >fit_mb</th>\n",
       "      <td id=\"T_f44e9_row1_col0\" class=\"data row1 col0\" >0.538000</td>\n",
       "      <td id=\"T_f44e9_row1_col1\" class=\"data row1 col1\" >0.460000</td>\n",
       "      <td id=\"T_f44e9_row1_col2\" class=\"data row1 col2\" >0.684000</td>\n",
       "      <td id=\"T_f44e9_row1_col3\" class=\"data row1 col3\" >0.684000</td>\n",
       "      <td id=\"T_f44e9_row1_col4\" class=\"data row1 col4\" >0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row2\" class=\"row_heading level0 row2\" >fit_habit</th>\n",
       "      <td id=\"T_f44e9_row2_col0\" class=\"data row2 col0\" >0.496000</td>\n",
       "      <td id=\"T_f44e9_row2_col1\" class=\"data row2 col1\" >0.555000</td>\n",
       "      <td id=\"T_f44e9_row2_col2\" class=\"data row2 col2\" >0.457000</td>\n",
       "      <td id=\"T_f44e9_row2_col3\" class=\"data row2 col3\" >0.637000</td>\n",
       "      <td id=\"T_f44e9_row2_col4\" class=\"data row2 col4\" >0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row3\" class=\"row_heading level0 row3\" >test_nlp_wsls</th>\n",
       "      <td id=\"T_f44e9_row3_col0\" class=\"data row3 col0\" >0.465000</td>\n",
       "      <td id=\"T_f44e9_row3_col1\" class=\"data row3 col1\" >0.571000</td>\n",
       "      <td id=\"T_f44e9_row3_col2\" class=\"data row3 col2\" >0.478000</td>\n",
       "      <td id=\"T_f44e9_row3_col3\" class=\"data row3 col3\" >0.490000</td>\n",
       "      <td id=\"T_f44e9_row3_col4\" class=\"data row3 col4\" >0.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row4\" class=\"row_heading level0 row4\" >fit_kdh</th>\n",
       "      <td id=\"T_f44e9_row4_col0\" class=\"data row4 col0\" >0.701000</td>\n",
       "      <td id=\"T_f44e9_row4_col1\" class=\"data row4 col1\" >0.694000</td>\n",
       "      <td id=\"T_f44e9_row4_col2\" class=\"data row4 col2\" >0.712000</td>\n",
       "      <td id=\"T_f44e9_row4_col3\" class=\"data row4 col3\" >0.695000</td>\n",
       "      <td id=\"T_f44e9_row4_col4\" class=\"data row4 col4\" >0.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f44e9_level0_row5\" class=\"row_heading level0 row5\" >fit_logistic_regression</th>\n",
       "      <td id=\"T_f44e9_row5_col0\" class=\"data row5 col0\" >0.461000</td>\n",
       "      <td id=\"T_f44e9_row5_col1\" class=\"data row5 col1\" >0.524000</td>\n",
       "      <td id=\"T_f44e9_row5_col2\" class=\"data row5 col2\" >0.476000</td>\n",
       "      <td id=\"T_f44e9_row5_col3\" class=\"data row5 col3\" >0.487000</td>\n",
       "      <td id=\"T_f44e9_row5_col4\" class=\"data row5 col4\" >0.619000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29db8d9ec70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = ['mf','mb','habit','wsls','kdh']\n",
    "all_df = []\n",
    "for m in Model:\n",
    "    df = pd.read_csv(f'../results/{m}/{m}_fit.csv')\n",
    "    col = [name for name in df.columns if 'test_nlp' in name]\n",
    "    df = pd.DataFrame(df[col].describe().loc['mean'])\n",
    "    df.rename(columns={'mean':f'true_{m}'},inplace=True) \n",
    "    df = df.round(3)\n",
    "    all_df.append(df)\n",
    "    \n",
    "d = pd.concat(all_df, axis=1)\n",
    "\n",
    "d.rename(index={'test_nlp_mf':'fit_mf',\n",
    "                'test_nlp_mb':'fit_mb',\n",
    "                'test_nlp_habit':'fit_habit',\n",
    "                'test_nlp_lwsls':'fit_wsls',\n",
    "                'test_nlp_kdh':'fit_kdh',\n",
    "                'test_nlp_logistic_regression':'fit_logistic_regression'},inplace=True)\n",
    "lr = pd.DataFrame(d.iloc[5])\n",
    "\n",
    "d.style.background_gradient(cmap ='viridis').set_properties(**{'font-size': '20px'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
